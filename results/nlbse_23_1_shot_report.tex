\begin{table}[ht!]
\centering
\caption{F1-Score Comparison Across Models}
\begin{tabular}{lccccc}
\hline
Model & documentation & question & feature & bug & micro avg & Micro F1 & Macro F1 \\
\hline
Qwen2-72B-Instruct & 0.81 & 0.72 & 0.82 & 0.84 & 0.80 & 0.80 \\
gpt-4o-2024-05-13 & 0.71 & 0.59 & 0.85 & 0.74 & 0.74 & 0.72 \\
Mixtral-8x7B-Instruct-v0.1 & 0.42 & 0.54 & 0.72 & 0.54 & 0.58 & 0.58 & 0.55 \\
Codestral-22B-v0.1 & 0.20 & 0.49 & 0.55 & 0.60 & 0.52 & 0.52 & 0.46 \\
CodeLlama-7b-Instruct-hf & 0.31 & 0.30 & 0.50 & 0.22 & 0.38 & 0.38 & 0.33 \\
deepseek-coder-33b-instruct & 0.30 & 0.00 & 0.45 & 0.45 & 0.37 & 0.37 & 0.30 \\
starcoder2-7b & 0.42 & 0.07 & 0.03 & 0.38 & 0.28 & 0.28 & 0.23 \\
Meta-Llama-3-8B-Instruct & 0.00 & 0.21 & 0.10 & 0.44 & 0.31 & 0.31 & 0.19 \\
Mistral-7B-Instruct-v0.3 & 0.00 & 0.12 & 0.10 & 0.45 & 0.32 & 0.17 \\
gpt-3.5-turbo & 0.00 & 0.00 & 0.00 & 0.66 & 0.26 & 0.26 & 0.16 \\
CodeLlama-34b-Instruct-hf & 0.00 & 0.21 & 0.04 & 0.40 & 0.26 & 0.26 & 0.16 \\
zephyr-7b-beta & 0.00 & 0.04 & 0.12 & 0.44 & 0.29 & 0.29 & 0.15 \\
CodeLlama-13b-Instruct-hf & 0.00 & 0.15 & 0.00 & 0.44 & 0.29 & 0.29 & 0.15 \\
Qwen2-7B-Instruct & 0.06 & 0.00 & 0.10 & 0.41 & 0.27 & 0.27 & 0.14 \\
Meta-Llama-3-70B-Instruct & 0.00 & 0.08 & 0.04 & 0.44 & 0.29 & 0.29 & 0.14 \\
deepseek-coder-6.7b-instruct & 0.00 & 0.04 & 0.00 & 0.44 & 0.28 & 0.12 \\
gemma-7b-it & 0.00 & 0.04 & 0.00 & 0.43 & 0.28 & 0.28 & 0.12 \\
Mistral-7B-Instruct-v0.2 & 0.00 & 0.00 & 0.00 & 0.44 & 0.28 & 0.11 \\
starcoder2-15b & 0.00 & 0.00 & 0.00 & 0.37 & 0.22 & 0.22 & 0.09 \\
CodeLlama-70b-Instruct-hf & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
Llama-2-13b-chat-hf & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
Llama-2-70b-chat-hf & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
deepseek-coder-7b-instruct-v1.5 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
Llama-2-7b-chat-hf & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
\hline
\end{tabular}
\end{table}
